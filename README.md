# VeriChain ğŸ”—

**AI Content Authenticity Verification System**

VeriChain is a decentralized platform for verifying the authenticity of AI-generated content using machine learning models and blockchain technology. This project is currently in the pre-contract phase, focusing on the core ML infrastructure and services.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Service  â”‚    â”‚ Inference       â”‚    â”‚ ML Training     â”‚
â”‚   (Next.js)    â”‚â—„â”€â”€â–ºâ”‚ Service         â”‚â—„â”€â”€â–ºâ”‚ (Python + TF)   â”‚
â”‚   - OpenAI     â”‚    â”‚ - ONNX Runtime  â”‚    â”‚ - TensorFlow    â”‚
â”‚   - Chat API   â”‚    â”‚ - Image Proc    â”‚    â”‚ - Model Export  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SDK Package   â”‚    â”‚ Relayer Stub    â”‚    â”‚ Smart Contracts â”‚
â”‚   (TypeScript)  â”‚    â”‚ (Future:        â”‚    â”‚ (Future:        â”‚
â”‚   - Shared      â”‚    â”‚   Blockchain    â”‚    â”‚   Solidity)     â”‚
â”‚   - Types      â”‚    â”‚   Integration)   â”‚    â”‚   - FuelToken   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ and Yarn
- Python 3.10+ (for ML training)
- Conda or virtual environment
- OpenAI API key (for chat functionality)

### 1. Install Dependencies

```bash
# Install all workspace dependencies
yarn install

# Build the SDK package
yarn workspace @verichain/sdk-js build
```

### 2. Set Up Environment Variables

```bash
# Create .env files for each service
echo "OPENAI_API_KEY=your_openai_key_here" > apps/web/.env
echo "MODEL_PATH=./models/model.onnx" > apps/inference/.env
```

### 3. Start Services

```bash
# Terminal 1: Web service (OpenAI + verification)
yarn workspace web dev

# Terminal 2: Inference service (ONNX model serving)
yarn workspace inference dev

# Terminal 3: Relayer stub (future blockchain integration)
yarn workspace relayer dev
```

### 4. Train ML Model

```bash
# Set up Python environment
cd ml/train
conda env create -f env.yml
conda activate verichain-ml

# Or use pip
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Start Jupyter and run training
jupyter notebook notebooks/01_train.ipynb
```

> ğŸ“˜ **For detailed ML pipeline documentation, see [ml/train/README.md](ml/train/README.md)**

### 5. Test the System

```bash
# Run end-to-end tests
node test-verification.js

# Or test individual services
curl http://localhost:3000/healthz
curl http://localhost:3001/healthz
```

## ğŸ“ Project Structure

```
verichain/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/                 # Next.js web service
â”‚   â”‚   â”œâ”€â”€ server.js        # Express server with OpenAI
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”œâ”€â”€ inference/           # ONNX inference service
â”‚   â”‚   â”œâ”€â”€ server.js        # Express + ONNX runtime
â”‚   â”‚   â”œâ”€â”€ models/          # ONNX model storage
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â””â”€â”€ relayer/             # Future blockchain integration
â”‚       â”œâ”€â”€ relayer.stub.js  # Stub implementation
â”‚       â””â”€â”€ package.json
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ sdk-js/              # Shared TypeScript SDK
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ types.ts     # Shared type definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ client.ts    # Client SDK
â”‚   â”‚   â”‚   â””â”€â”€ index.ts     # Main exports
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â””â”€â”€ contracts/           # Hardhat workspace (existing)
â”œâ”€â”€ ml/
â”‚   â””â”€â”€ train/               # ML training pipeline
â”‚       â”œâ”€â”€ env.yml          # Conda environment
â”‚       â”œâ”€â”€ requirements.txt # Pip dependencies
â”‚       â””â”€â”€ notebooks/       # Jupyter notebooks
â”œâ”€â”€ test-verification.js     # End-to-end test script
â””â”€â”€ README.md
```

## ğŸ”§ Service Details

### Web Service (`apps/web`)

- **Port**: 3000
- **Purpose**: OpenAI integration and verification orchestration
- **Endpoints**:
  - `POST /api/chat` - OpenAI chat completion (streaming)
  - `POST /api/verify` - Image verification (forwards to inference)
  - `GET /healthz` - Health check
  - `GET /metrics` - Service metrics

### Inference Service (`apps/inference`)

- **Port**: 3001
- **Purpose**: ONNX model serving for image classification
- **Endpoints**:
  - `POST /infer` - Image inference endpoint
  - `GET /healthz` - Health check
  - `GET /metrics` - Model and service metrics

### ML Training (`ml/train`)

- **Purpose**: Train and export ML models for authenticity detection
- **Pipeline**:
  1. Load and preprocess image dataset
  2. Train CNN classifier (real vs AI-generated)
  3. Export to ONNX format
  4. Generate model metadata and hash
- **Documentation**: ğŸ“˜ [Detailed ML Pipeline README](ml/train/README.md) - Complete training, conversion, and inference documentation

### SDK Package (`packages/sdk-js`)

- **Purpose**: Shared types and client utilities
- **Features**:
  - TypeScript type definitions
  - Client SDK for service interaction
  - Content hash calculation utilities
  - Verification flow orchestration

## ğŸ§ª Testing

### Manual Testing

```bash
# Test OpenAI chat
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"messages":[{"role":"user","content":"Hello"}]}'

# Test image verification
curl -X POST http://localhost:3000/api/verify \
  -H "Content-Type: application/json" \
  -d '{"imageUrl":"https://example.com/image.jpg"}'

# Test inference directly
curl -X POST http://localhost:3001/infer \
  -H "Content-Type: application/json" \
  -d '{"imageUrl":"https://example.com/image.jpg"}'
```

### Automated Testing

```bash
# Run end-to-end tests
node test-verification.js

# Test with custom URLs
node test-verification.js --web-url http://localhost:3000 --inference-url http://localhost:3001
```

## ğŸ“Š Monitoring & Observability

### Logging

All services use structured logging with Pino:
- **Trace IDs**: Every request gets a unique trace ID
- **Structured logs**: JSON format with consistent fields
- **Pretty printing**: Human-readable logs in development

### Health Checks

```bash
# Web service health
curl http://localhost:3000/healthz

# Inference service health
curl http://localhost:3001/healthz
```

### Metrics

```bash
# Service metrics
curl http://localhost:3000/metrics
curl http://localhost:3001/metrics
```

## ğŸ”® Future Roadmap

### Phase 2: Smart Contracts (Next Sprint)

- **FuelToken.sol**: ERC20 token for verification fees
- **ProofRegistry.sol**: On-chain proof storage
- **Validator contracts**: Staking and reward mechanisms

### Phase 3: Advanced Features

- **Video processing**: Support for video authenticity detection
- **Model marketplace**: Decentralized model distribution
- **Validator network**: Distributed verification consensus
- **Mobile SDK**: React Native and Flutter support

## ğŸ› Troubleshooting

### Common Issues

1. **Port conflicts**: Ensure ports 3000 and 3001 are available
2. **ONNX model missing**: Train and export model first, then copy to `apps/inference/models/`
3. **OpenAI API errors**: Check API key and billing status
4. **Python environment**: Ensure correct Python version and dependencies

### Debug Mode

```bash
# Enable debug logging
DEBUG=* yarn workspace web dev
DEBUG=* yarn workspace inference dev
```

### Service Dependencies

```bash
# Check service health
yarn workspace web health
yarn workspace inference health

# View logs
yarn workspace web logs
yarn workspace inference logs
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ†˜ Support

- **Issues**: GitHub Issues
- **Discussions**: GitHub Discussions
- **Documentation**: This README and inline code comments

---

**Status**: Pre-contract phase - Core ML infrastructure complete, smart contracts next sprint.
**Next Milestone**: Smart contract development and on-chain integration.
